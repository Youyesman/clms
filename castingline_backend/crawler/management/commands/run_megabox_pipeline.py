import os
import time
import json
import requests
import re
from datetime import datetime
from django.conf import settings
from django.db import close_old_connections
from django.core.management.base import BaseCommand
from playwright.sync_api import sync_playwright

# Models Import
from crawler.models import MegaboxScheduleLog, MovieSchedule

# =============================================================================
# [PART 1] RPA Logic (Megabox)
# =============================================================================

from concurrent.futures import ThreadPoolExecutor

# =============================================================================
# [PART 1] RPA Logic (Megabox)
# =============================================================================

def fetch_megabox_schedule_rpa(date_list=None, target_regions=None, stop_signal=None):
    """
    Playwrightë¥¼ ì‚¬ìš©í•˜ì—¬ Megabox íŽ˜ì´ì§€ì— ì ‘ì†í•˜ê³ , 
    ì§€ì—­ -> ê·¹ìž¥ -> [ë‚ ì§œ ë¦¬ìŠ¤íŠ¸] ìˆœìœ¼ë¡œ ìˆœíšŒí•˜ë©° ë°ì´í„° ìˆ˜ì§‘ ì¦‰ì‹œ DBì— ì €ìž¥í•©ë‹ˆë‹¤.
    (Theater-First Approach)
    
    :param target_regions: List of region names to process (e.g., ["ì„œìš¸", "ì¸ì²œ"]). If None, process all.
    """
    if date_list is None:
        date_list = [datetime.now().strftime("%Y%m%d")]

    collected_results = []
    failures = [] # ì‹¤íŒ¨ ë‚´ì—­
    total_theater_count = 0  
    
    # Thread Safe ì„¤ì •
    os.environ["DJANGO_ALLOW_ASYNC_UNSAFE"] = "true"
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        # Browser Context isolated for each worker
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
        )
        page = context.new_page()

        target_url = "https://www.megabox.co.kr/booking/timetable"
        worker_id = "Global" if not target_regions else f"Worker({target_regions[0]}...)"
        print(f"[{worker_id}] ðŸš€ Navigating to: {target_url}")
        
        try:
            # print("   Accessible URL...")
            page.goto(target_url, timeout=60000)
            page.wait_for_load_state("domcontentloaded")
            time.sleep(3) # Initial render wait
            
            # 1. 'ê·¹ìž¥ë³„' íƒ­ í´ë¦­
            theater_tab_sel = "a[href='#masterBrch']" 
            
            try:
                page.wait_for_selector(theater_tab_sel, timeout=10000)
                page.click(theater_tab_sel, force=True)
                time.sleep(2)
            except Exception as e:
                print(f"[{worker_id}] âš ï¸ Tab click failed: {e}")
                # page.screenshot(path=f"megabox_tab_error_{worker_id}.png")

            # 2. ì§€ì—­ ìˆœíšŒ
            region_list_sel = "#masterBrch .tab-list-choice a"
            
            # Retry loop for region list
            for _ in range(3):
                if page.locator(region_list_sel).count() > 0:
                    break
                time.sleep(2)
                
            region_count = page.locator(region_list_sel).count()
            if region_count == 0:
                 print(f"[{worker_id}] âš ï¸ Region list count is 0.")
            
            # print(f"[{worker_id}] ðŸ“ Found {region_count} regions available on page.")
            
            for i in range(region_count):
                try:
                    if stop_signal: stop_signal()
                    # ì§€ì—­ ë²„íŠ¼ í´ë¦­
                    region_btn = page.locator(f"{region_list_sel}").nth(i)
                    raw_region_name = region_btn.inner_text().split('\n')[0].strip()
                    # Remove count (e.g. "ì„œìš¸(19)" -> "ì„œìš¸")
                    region_name = re.sub(r'\(\d+\)$', '', raw_region_name).strip()
                    
                    # --- Region Filtering Logic ---
                    if target_regions:
                        if region_name not in target_regions:
                             # print(f"[{worker_id}] Skipping '{region_name}' (Not in target)")
                             continue
                    
                    print(f"\n[{worker_id}] Processing Region: {region_name} (Raw: {raw_region_name})")
                    
                    region_btn.scroll_into_view_if_needed()
                    region_btn.click(force=True)
                    time.sleep(1.0) # ë¦¬ìŠ¤íŠ¸ ê°±ì‹  ëŒ€ê¸°
                    
                    # 3. ê·¹ìž¥ ìˆœíšŒ - í™œì„±í™”ëœ íƒ­ì˜ ê·¹ìž¥ë§Œ ì„ íƒ
                    theater_list_sel = "#masterBrch .tab-layer-cont.on button"
                    
                    # í•´ë‹¹ ì§€ì—­ì— ê·¹ìž¥ì´ ìžˆëŠ”ì§€ í™•ì¸
                    try:
                        page.wait_for_selector(theater_list_sel, timeout=5000)
                    except:
                        print(f"[{worker_id}] âš ï¸ No theaters found in {region_name} or timeout.")
                        continue
                    
                    theater_count = page.locator(theater_list_sel).count()
                    total_theater_count += theater_count
                    print(f"[{worker_id}]    Found {theater_count} theaters in {region_name}")
                    
                    for j in range(theater_count):
                        try:
                            if stop_signal: stop_signal()
                            theater_btn = page.locator(theater_list_sel).nth(j)
                            theater_name = theater_btn.inner_text().strip()
                            brch_no = theater_btn.get_attribute("data-brch-no") or "Unknown"
                            
                            print(f"[{worker_id}]       Processing: {theater_name} ({brch_no})")
                            
                            # 1. ê·¹ìž¥ ì„ íƒ
                            theater_btn.click(force=True)
                            time.sleep(1)

                            # 2. ë‚ ì§œ ìˆœíšŒ (Theater-First Logic)
                            for scn_ymd in date_list:
                                if stop_signal: stop_signal()
                                
                                # Megabox: .date-list button[date-data='2024.01.29']
                                target_date_fmt = f"{scn_ymd[:4]}.{scn_ymd[4:6]}.{scn_ymd[6:]}" # YYYY.MM.DD
                                
                                try:
                                    # ì •í™•í•œ ì†ì„± ê¸°ë°˜ ì°¾ê¸°
                                    date_btn = page.locator(f"button[date-data='{target_date_fmt}']").first
                                    
                                    if date_btn.count() == 0:
                                        target_day = str(int(scn_ymd[6:]))
                                        date_btn = page.locator(f".date-list button:has-text('{target_day}')").first

                                    if date_btn.count() > 0:
                                        is_active = "on" in (date_btn.get_attribute("class") or "")
                                        
                                        # í´ë¦­ ë° ì‘ë‹µ ëŒ€ê¸°
                                        with page.expect_response(lambda response: "schedulePage.do" in response.url, timeout=5000) as response_info:
                                            date_btn.click(force=True)
                                        
                                        response = response_info.value
                                        
                                        if response.status == 200:
                                            try:
                                                json_data = response.json()
                                                close_old_connections()
                                                
                                                log = MegaboxScheduleLog.objects.create(
                                                    query_date=scn_ymd,
                                                    site_code=brch_no,
                                                    theater_name=theater_name,
                                                    response_json=json_data,
                                                    status='success'
                                                )
                                                # print(f"[{worker_id}]          âœ… Saved: {scn_ymd}")
                                                collected_results.append({"log_id": log.id})
                                                
                                            except Exception as e:
                                                print(f"[{worker_id}]          âŒ Parse Error {scn_ymd}: {e}")
                                        else:
                                            print(f"[{worker_id}]          âš ï¸ Status: {response.status}")
                                            
                                    else:
                                        print(f"[{worker_id}]       âš ï¸ Date button not found. Skipping.")
                                        failures.append({
                                            'region': region_name,
                                            'theater': theater_name,
                                            'date': scn_ymd,
                                            'reason': "Date Button Not Found",
                                            'worker': worker_id
                                        })
                                        
                                except Exception as e:
                                    print(f"[{worker_id}]       âš ï¸ Date Error {scn_ymd}: {e}")
                                    failures.append({
                                        'region': region_name,
                                        'theater': theater_name,
                                        'date': scn_ymd,
                                        'reason': f"Error: {str(e)[:50]}",
                                        'worker': worker_id
                                    })
                                
                                time.sleep(0.1) 

                        except InterruptedError:
                            raise
                        except Exception as e:
                            print(f"[{worker_id}]       âŒ Theater Error: {e}")
                            continue

                except InterruptedError:
                    raise
                except Exception as e:
                    print(f"[{worker_id}] âŒ Region Error: {e}")
                    continue

        except Exception as e:
            print(f"[{worker_id}] âŒ Playwright Error: {e}")

    print(f"[{worker_id}] Finished. Collected: {len(collected_results)}")
    return collected_results, failures, total_theater_count


# =============================================================================
# [PART 2] Pipeline Service Logic (Megabox)
# =============================================================================

class MegaboxPipelineService:
    @staticmethod
    def collect_schedule_logs(dates=None, stop_signal=None):
        os.environ["DJANGO_ALLOW_ASYNC_UNSAFE"] = "true"
        if not dates:
            dates = [datetime.now().strftime("%Y%m%d")]

        # Region Grouping for Parallel Execution
        # ê° workerê°€ ë‹´ë‹¹í•  ì§€ì—­ ë¦¬ìŠ¤íŠ¸
        REGION_GROUPS = [
            ["ì„œìš¸", "ì¸ì²œ", "ê°•ì›", "ëŒ€ì „/ì¶©ì²­/ì„¸ì¢…"],  # Worker 1
            ["ê²½ê¸°", "ë¶€ì‚°/ëŒ€êµ¬/ê²½ìƒ", "ê´‘ì£¼/ì „ë¼", "ì œì£¼"]  # Worker 2
        ]

        print(f"--- Pipeline: Collecting for dates {dates} (Parallel Execution with {len(REGION_GROUPS)} Workers) ---")
        
        collected_logs = []
        all_failures = []
        total_detected_cnt = 0
        
        with ThreadPoolExecutor(max_workers=len(REGION_GROUPS)) as executor:
            futures = []
            for group_idx, region_group in enumerate(REGION_GROUPS):
                print(f"[Main] Scheduling Worker-{group_idx+1} for regions: {region_group}")
                futures.append(
                    executor.submit(
                        fetch_megabox_schedule_rpa, 
                        date_list=dates, 
                        target_regions=region_group, 
                        stop_signal=stop_signal
                    )
                )
            
            # Wait for all futures
            for future in futures:
                try:
                    res_logs, res_failures, res_cnt = future.result()
                    collected_logs.extend(res_logs)
                    all_failures.extend(res_failures)
                    total_detected_cnt += res_cnt
                except Exception as e:
                    print(f"[Main] âŒ One of the workers failed: {e}")
        
        return collected_logs, total_detected_cnt, all_failures

    @classmethod
    def check_missing_theaters(cls, logs, total_expected):
        collected_cnt = len(logs)
        # ë‹¨ìˆœ ìˆ˜ì§‘ ì¹´ìš´íŠ¸ ë¹„êµ (ë‚ ì§œë³„ * ê·¹ìž¥ìˆ˜ ê³ ë ¤ í•„ìš”í•˜ë‚˜ ì¼ë‹¨ ë‹¨ìˆœ ë¹„êµ)
        # ë¡œê·¸ ìˆ˜ = ê·¹ìž¥ ìˆ˜ * ë‚ ì§œ ìˆ˜ ì—¬ì•¼ í•¨. 
        # total_expectedëŠ” 'ë°œê²¬ëœ ê·¹ìž¥ ìˆ˜' ì´ë¯€ë¡œ, ë‚ ì§œ ìˆ˜ë¥¼ ëª¨ë¥´ë©´ ì •í™•í•œ ë¹„êµ ë¶ˆê°€.
        # ì—¬ê¸°ì„  'ìµœì†Œí•œ ê·¹ìž¥ ìˆ˜ë³´ë‹¤ëŠ” ë§Žì•„ì•¼ í•œë‹¤' ì •ë„ë¡œ ì²´í¬í•˜ê±°ë‚˜, ìŠ¤í‚µ.
        
        missing_count = total_expected - collected_cnt # This logic might need adjustment for multi-date
        is_missing = False # Disable missing check strictly for now as logic changed
        
        return {
            'is_missing': is_missing,
            'total_cnt': total_expected,
            'collected_cnt': collected_cnt,
            'missing_cnt': max(0, missing_count)
        }

    @staticmethod
    def transform_logs_to_schedule(log_ids=None, target_titles=None):
        if log_ids:
            logs = MegaboxScheduleLog.objects.filter(id__in=log_ids)
        else:
            logs = MegaboxScheduleLog.objects.filter(created_at__date=datetime.now().date())
            
        print(f"   [Transform] Processing {logs.count()} logs...")

        total_created = 0
        all_errors = []
        
        for log in logs:
            try:
                cnt, errors = MovieSchedule.create_from_megabox_log(log, target_titles=target_titles)
                total_created += cnt
                all_errors.extend(errors)
            except Exception as e:
                print(f"Error transforming log {log.id}: {e}")
                all_errors.append({
                    'theater': log.theater_name,
                    'site_code': log.site_code,
                    'movie': 'N/A',
                    'error': str(e),
                    'log_id': log.id
                })
        
        return total_created, all_errors

    @classmethod
    def send_slack_message(cls, message_type, data):
        token = getattr(settings, 'SLACK_BOT_TOKEN', '')
        channel = getattr(settings, 'SLACK_CHANNEL_ID', '')
        
        if not token or not channel:
            print(f"[Slack LOG] {message_type}: {data}")
            return
        
        text = ""
        blocks = []

        if message_type == "INFO":
            text = f"â„¹ï¸ Pipeline: {data['message']}"
            blocks = [
                {
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": f"*â„¹ï¸ [Megabox] Status*\n{data['message']}"}
                }
            ]
            
        elif message_type == "SUCCESS":
            # ì‹¤íŒ¨ ë‚´ì—­ì´ ìžˆìœ¼ë©´ í•¨ê»˜ í‘œì‹œ
            failures = data.get('failures', [])
            fail_text = ""
            if failures:
                fail_summary = []
                for f in failures[:15]: # ìµœëŒ€ 15ê°œê¹Œì§€ë§Œ
                    reason = f.get('reason', 'Unknown')
                    fail_summary.append(f"â€¢ [{f['theater']}] {f['date']}: {reason}")
                
                if len(failures) > 15:
                    fail_summary.append(f"... ì™¸ {len(failures)-15}ê±´")
                
                fail_text = "\n\nâš ï¸ *ìˆ˜ì§‘ ì‹¤íŒ¨ ê·¹ìž¥ ë¦¬ìŠ¤íŠ¸:*\n" + "\n".join(fail_summary)

            text = f"âœ… ë©”ê°€ë°•ìŠ¤ ìŠ¤ì¼€ì¤„ íŒŒì´í”„ë¼ì¸ ì„±ê³µ! (ìˆ˜ì§‘: {data['collected']}, ìƒì„±: {data['created']})"
            blocks = [
                {
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": f"*âœ… ë©”ê°€ë°•ìŠ¤ ìŠ¤ì¼€ì¤„ íŒŒì´í”„ë¼ì¸ ì„±ê³µ!*"}
                },
                {
                    "type": "section",
                    "fields": [
                        {"type": "mrkdwn", "text": f"*ìˆ˜ì§‘ëœ ë¡œê·¸:*\n{data['collected']}ê°œ"},
                        {"type": "mrkdwn", "text": f"*ìƒì„±ëœ ìŠ¤ì¼€ì¤„:*\n{data['created']}ê°œ"}
                    ]
                }
            ]
            
            if failures:
                blocks.append({
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": fail_text}
                })
            
        elif message_type == "WARNING_MISSING":
            text = f"âš ï¸ ë©”ê°€ë°•ìŠ¤ ìŠ¤ì¼€ì¤„ ìˆ˜ì§‘ ëˆ„ë½ ê²½ê³ ! ({data['collected_cnt']}/{data['total_cnt']})"
            blocks = [
                {
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": f"*âš ï¸ ë©”ê°€ë°•ìŠ¤ ìŠ¤ì¼€ì¤„ ìˆ˜ì§‘ ëˆ„ë½ ê²½ê³ !*"}
                }
            ]
            
        elif message_type == "ERROR":
            error_count = len(data.get('errors', []))
            text = f"âŒ ë©”ê°€ë°•ìŠ¤ íŒŒì‹± ì—ëŸ¬ ë°œìƒ! ({error_count}ê±´)"
            
            error_summary = "\n".join([
                f"â€¢ {err['theater']} - {err['movie']}: {err['error'][:50]}"
                for err in data.get('errors', [])[:5]
            ])
            
            blocks = [
                {
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": f"*âŒ ë©”ê°€ë°•ìŠ¤ ë°ì´í„° íŒŒì‹± ì—ëŸ¬ ë°œìƒ!*"}
                },
                {
                    "type": "section",
                    "fields": [
                        {"type": "mrkdwn", "text": f"*ì´ ì—ëŸ¬ ìˆ˜:*\n{error_count}ê±´"},
                        {"type": "mrkdwn", "text": f"*ì˜í–¥ë°›ì€ ê·¹ìž¥:*\n{len(set(e['theater'] for e in data.get('errors', [])))}ê°œ"}
                    ]
                },
                {
                    "type": "section",
                    "text": {"type": "mrkdwn", "text": f"*ì—ëŸ¬ ìƒ˜í”Œ (ìµœëŒ€ 5ê±´):*\n{error_summary}"}
                }
            ]

        try:
            url = "https://slack.com/api/chat.postMessage"
            headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
            payload = {"channel": channel, "text": text, "blocks": blocks}
            requests.post(url, headers=headers, json=payload)
        except Exception as e:
            print(f"Slack Send Error: {e}")

    @classmethod
    def run_pipeline(cls, target_dates=None):
        print(">>> Starting Megabox Pipeline")
        cls.send_slack_message("INFO", {"message": "ðŸš€ ë©”ê°€ë°•ìŠ¤ ìŠ¤ì¼€ì¤„ ìˆ˜ì§‘ ì‹œìž‘"})
        
        logs, total_cnt, collection_failures = cls.collect_schedule_logs(dates=target_dates)
        log_ids = [l['log_id'] for l in logs if isinstance(l, dict) and 'log_id' in l]
        
        fail_msg = f"\nâš ï¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {len(collection_failures)}ê±´" if collection_failures else ""
        cls.send_slack_message("INFO", {"message": f"ðŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ.\n- ìˆ˜ì§‘ëœ ë¡œê·¸: {len(logs)}ê°œ\n- ë°œê²¬ëœ ê·¹ìž¥: {total_cnt}ê°œ{fail_msg}\nê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."})
        
        # Validation Logic needs to be smarter for multi-date, but keeping basic for now
        # check_result = cls.check_missing_theaters(logs, total_cnt)
        # if check_result['is_missing']:
        #     cls.send_slack_message("WARNING_MISSING", check_result)
        
        # [USER REQUEST] ë°ì´í„° ìƒì„± ìž ì‹œ ì¤‘ë‹¨
        created_cnt = 0
        errors = []
        # created_cnt, errors = cls.transform_logs_to_schedule(log_ids, target_titles=None)
        
        # Send error report if any
        if errors:
            cls.send_slack_message("ERROR", {"errors": errors})
        
        cls.send_slack_message("SUCCESS", {
            "collected": len(logs), 
            "created": created_cnt,
            "failures": collection_failures
        })


# =============================================================================
# [PART 3] Django Management Command
# =============================================================================

class Command(BaseCommand):
    help = 'Executes the Megabox Pipeline (Collect -> Validate -> Notify)'

    def add_arguments(self, parser):
        parser.add_argument('--date', type=str, help='Single Target Date (YYYYMMDD)')
        parser.add_argument('--start-date', type=str, help='Start Date (YYYYMMDD)')
        parser.add_argument('--end-date', type=str, help='End Date (YYYYMMDD)')

    def handle(self, *args, **options):
        self.stdout.write("Initializing Megabox Pipeline...")
        
        target_dates = []
        if options.get('date'):
            target_dates = [options.get('date')]
        elif options.get('start_date') and options.get('end_date'):
            start = datetime.strptime(options['start_date'], "%Y%m%d")
            end = datetime.strptime(options['end_date'], "%Y%m%d")
            delta = end - start
            for i in range(delta.days + 1):
                day = start + timedelta(days=i)
                target_dates.append(day.strftime("%Y%m%d"))
        else:
             target_dates = [datetime.now().strftime("%Y%m%d")]

        from datetime import timedelta # Need import
        
        try:
            MegaboxPipelineService.run_pipeline(target_dates=target_dates)
            self.stdout.write(self.style.SUCCESS("Pipeline execution finished."))
        except Exception as e:
            self.stdout.write(self.style.ERROR(f"Pipeline failed: {e}"))
            import traceback
            traceback.print_exc()
